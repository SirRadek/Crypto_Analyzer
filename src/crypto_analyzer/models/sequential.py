"""Lightweight sequential models for medium-term crypto horizons.

The default modelling stack focuses on tree ensembles which work well on
tabular features.  For 15-minute sampled data that needs to capture
dependencies over two to six hour horizons a compact neural architecture is
useful.  This module therefore provides two deliberately small models
implemented in PyTorch:

``TCNClassifier``
    A Temporal Convolutional Network consisting of dilated causal
    convolutions.  The receptive field can be scaled by adjusting the number
    of blocks and dilation base.
``TransformerClassifier``
    A transformer encoder with a handful of layers, intended for cases where
    the order of observations matters more than strict causality.

Both networks operate on sliding-window sequences generated by
``SequenceWindowDataset``.  Training utilities mirror the ergonomics of the
gradient boosting helper and return easy to inspect diagnostics.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Literal, Sequence

import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader, Dataset

__all__ = [
    "WindowConfig",
    "SequenceWindowDataset",
    "TCNConfig",
    "TransformerConfig",
    "TrainingConfig",
    "TCNClassifier",
    "TransformerClassifier",
    "train_sequence_classifier",
]


@dataclass(slots=True)
class WindowConfig:
    """Describe how sliding-window sequences are created."""

    window: int = 16
    horizon: int = 1

    def __post_init__(self) -> None:
        if self.window <= 0:
            raise ValueError("window must be positive")
        if self.horizon <= 0:
            raise ValueError("horizon must be positive")


class SequenceWindowDataset(Dataset[tuple[torch.Tensor, torch.Tensor]]):
    """Turn a 2D feature array into overlapping sequences."""

    def __init__(self, features: np.ndarray, targets: np.ndarray, config: WindowConfig):
        feats = np.asarray(features, dtype=np.float32)
        targs = np.asarray(targets, dtype=np.float32)
        if feats.ndim != 2:
            raise ValueError("features must be a 2D array")
        if len(feats) != len(targs):
            raise ValueError("features and targets must have the same length")
        self.features = feats
        self.targets = targs
        self.config = config

    def __len__(self) -> int:  # pragma: no cover - tiny one liner
        total = len(self.features) - self.config.window - self.config.horizon + 1
        return max(total, 0)

    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:
        start = idx
        end = idx + self.config.window
        label_idx = end + self.config.horizon - 1
        if label_idx >= len(self.targets):
            raise IndexError("index exceeds available targets")
        window = self.features[start:end]
        target = self.targets[label_idx]
        x = torch.from_numpy(window).float()
        y = torch.tensor(target, dtype=torch.float32)
        return x, y


@dataclass(slots=True)
class TCNConfig:
    """Hyper parameters controlling the Temporal Convolutional Network."""

    input_channels: int
    hidden_channels: int = 64
    num_blocks: int = 3
    kernel_size: int = 3
    dilation_base: int = 2
    dropout: float = 0.1

    def __post_init__(self) -> None:
        if self.input_channels <= 0:
            raise ValueError("input_channels must be positive")
        if self.hidden_channels <= 0:
            raise ValueError("hidden_channels must be positive")
        if self.num_blocks <= 0:
            raise ValueError("num_blocks must be positive")
        if self.kernel_size <= 1:
            raise ValueError("kernel_size must be > 1 for meaningful receptive field")
        if not 0.0 <= self.dropout < 1.0:
            raise ValueError("dropout must be in [0, 1)")


@dataclass(slots=True)
class TransformerConfig:
    """Configuration for the Transformer based classifier."""

    input_dim: int
    hidden_dim: int = 64
    num_layers: int = 2
    num_heads: int = 4
    dropout: float = 0.1

    def __post_init__(self) -> None:
        if self.input_dim <= 0:
            raise ValueError("input_dim must be positive")
        if self.hidden_dim <= 0:
            raise ValueError("hidden_dim must be positive")
        if self.num_layers <= 0:
            raise ValueError("num_layers must be positive")
        if self.num_heads <= 0:
            raise ValueError("num_heads must be positive")
        if not 0.0 <= self.dropout < 1.0:
            raise ValueError("dropout must be in [0, 1)")


@dataclass(slots=True)
class TrainingConfig:
    """Training hyper parameters shared by the sequential models."""

    window: WindowConfig
    epochs: int = 10
    batch_size: int = 64
    lr: float = 1e-3
    device: Literal["cpu", "cuda", "auto"] = "auto"

    def __post_init__(self) -> None:
        if self.epochs <= 0:
            raise ValueError("epochs must be positive")
        if self.batch_size <= 0:
            raise ValueError("batch_size must be positive")
        if self.lr <= 0:
            raise ValueError("learning rate must be positive")


class _CausalBlock(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, dilation: int, dropout: float):
        super().__init__()
        padding = (kernel_size - 1) * dilation
        self.conv = nn.Conv1d(
            in_channels,
            out_channels,
            kernel_size,
            padding=padding,
            dilation=dilation,
        )
        self.dropout = nn.Dropout(dropout)
        self.activation = nn.ReLU()
        self.resample = (
            nn.Conv1d(in_channels, out_channels, kernel_size=1)
            if in_channels != out_channels
            else nn.Identity()
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore[override]
        out = self.conv(x)
        crop = self.conv.dilation[0] * (self.conv.kernel_size[0] - 1)
        if crop > 0:
            out = out[..., :-crop]
        out = self.activation(out)
        out = self.dropout(out)
        res = self.resample(x)
        res = res[..., -out.size(-1) :]
        return out + res


class TCNClassifier(nn.Module):
    """Compact temporal convolutional classifier."""

    def __init__(self, config: TCNConfig):
        super().__init__()
        layers: list[nn.Module] = []
        in_channels = config.input_channels
        dilation = 1
        for _ in range(config.num_blocks):
            block = _CausalBlock(
                in_channels,
                config.hidden_channels,
                kernel_size=config.kernel_size,
                dilation=dilation,
                dropout=config.dropout,
            )
            layers.append(block)
            in_channels = config.hidden_channels
            dilation *= config.dilation_base
        self.network = nn.Sequential(*layers)
        self.head = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(config.hidden_channels, config.hidden_channels // 2),
            nn.ReLU(),
            nn.Linear(config.hidden_channels // 2, 1),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore[override]
        # Input arrives as (batch, window, features); conv1d expects channels first.
        x = x.transpose(1, 2)
        features = self.network(x)
        logits = self.head(features)
        return logits.squeeze(-1)


class TransformerClassifier(nn.Module):
    """Minimal transformer encoder for windowed price data."""

    def __init__(self, config: TransformerConfig, window: int):
        super().__init__()
        self.proj = nn.Linear(config.input_dim, config.hidden_dim)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=config.hidden_dim,
            nhead=config.num_heads,
            dropout=config.dropout,
            batch_first=True,
        )
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config.num_layers)
        self.positional = nn.Parameter(torch.zeros(1, window, config.hidden_dim))
        self.head = nn.Sequential(
            nn.Linear(config.hidden_dim, config.hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(config.hidden_dim // 2, 1),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore[override]
        pos = self.positional[:, : x.size(1), :]
        x = self.proj(x) + pos
        enc = self.encoder(x)
        pooled = enc.mean(dim=1)
        logits = self.head(pooled)
        return logits.squeeze(-1)


def _infer_device(requested: Literal["cpu", "cuda", "auto"]) -> torch.device:
    if requested == "auto":
        return torch.device("cuda" if torch.cuda.is_available() else "cpu")
    return torch.device(requested)


def train_sequence_classifier(
    features: np.ndarray,
    targets: np.ndarray,
    *,
    training: TrainingConfig,
    model: Literal["tcn", "transformer"] = "tcn",
    tcn_config: TCNConfig | None = None,
    transformer_config: TransformerConfig | None = None,
) -> tuple[nn.Module, dict[str, float]]:
    """Train either the TCN or transformer classifier on sliding windows."""

    dataset = SequenceWindowDataset(features, targets, training.window)
    if len(dataset) == 0:
        raise ValueError("dataset is empty â€“ increase the amount of data or reduce the window")

    split_idx = int(len(dataset) * 0.8)
    if split_idx == 0 or split_idx == len(dataset):
        split_idx = max(len(dataset) - 1, 1)
    train_subset, val_subset = torch.utils.data.random_split(dataset, [split_idx, len(dataset) - split_idx])

    train_loader = DataLoader(train_subset, batch_size=training.batch_size, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=training.batch_size)

    device = _infer_device(training.device)

    input_dim = features.shape[1]
    if model == "tcn":
        cfg = tcn_config or TCNConfig(input_channels=input_dim)
        net: nn.Module = TCNClassifier(cfg)
    elif model == "transformer":
        cfg = transformer_config or TransformerConfig(input_dim=input_dim)
        net = TransformerClassifier(cfg, training.window.window)
    else:  # pragma: no cover - defensive branch
        raise ValueError(f"Unsupported model '{model}'")

    net.to(device)
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(net.parameters(), lr=training.lr)

    metrics: dict[str, float] = {}
    for epoch in range(training.epochs):
        net.train()
        train_loss = 0.0
        for batch_x, batch_y in train_loader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            optimizer.zero_grad()
            logits = net(batch_x)
            loss = criterion(logits, batch_y)
            loss.backward()
            optimizer.step()
            train_loss += float(loss.detach().cpu()) * len(batch_x)
        train_loss /= len(train_loader.dataset)

        net.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for batch_x, batch_y in val_loader:
                batch_x = batch_x.to(device)
                batch_y = batch_y.to(device)
                logits = net(batch_x)
                loss = criterion(logits, batch_y)
                val_loss += float(loss.cpu()) * len(batch_x)
                preds = torch.sigmoid(logits) >= 0.5
                correct += int((preds == (batch_y >= 0.5)).sum().cpu())
                total += len(batch_x)
        val_loss /= len(val_loader.dataset)
        metrics[f"epoch_{epoch+1}_train_loss"] = train_loss
        metrics[f"epoch_{epoch+1}_val_loss"] = val_loss
        metrics[f"epoch_{epoch+1}_val_accuracy"] = correct / max(total, 1)

    return net, metrics

